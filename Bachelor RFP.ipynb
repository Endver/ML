{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b940825",
   "metadata": {},
   "source": [
    "# RFP: Betting on the Bachelor\n",
    "\n",
    "## Project Overview\n",
    "You are invited to submit a proposal that answers the following question:\n",
    "\n",
    "### Who will win season 29 of the Bachelor?\n",
    "\n",
    "*All proposals must be submitted by **1/15/25 at 11:59 PM**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a85f0",
   "metadata": {},
   "source": [
    "## Required Proposal Components\n",
    "\n",
    "### 1. Data Description\n",
    "In the code cell below, read in the data you plan on using to train and test your model. Call `info()` once you have read the data into a dataframe. Consider using some or all of the following sources:\n",
    "- [Scrape Fandom Wikis](https://bachelor-nation.fandom.com/wiki/The_Bachelor) or [the official Bachelor website]('https://bachelornation.com/shows/the-bachelor/')\n",
    "- [Ask ChatGPT to genereate it](https://chatgpt.com/)\n",
    "- [Read in csv files like this](https://www.kaggle.com/datasets/brianbgonz/the-bachelor-contestants?select=contestants.csv)\n",
    "\n",
    "*Note, a level 5 dataset contains at least 1000 rows of non-null data. A level 4 contains at least 500 rows of non-null data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c1688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79999d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Show Name        1000 non-null   object\n",
      " 1   Contestant Name  1000 non-null   object\n",
      " 2   Winner/Loser     1000 non-null   object\n",
      " 3   Season           1000 non-null   int64 \n",
      " 4   Age              1000 non-null   int64 \n",
      " 5   Occupation       1000 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"shows_contestants_1000_rows.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2125b2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Name</th>\n",
       "      <th>Contestant Name</th>\n",
       "      <th>Winner/Loser</th>\n",
       "      <th>Season</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelor in Paradise</td>\n",
       "      <td>Jade Roper</td>\n",
       "      <td>Loser</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Event Planner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bachelor</td>\n",
       "      <td>Lauren Bushnell</td>\n",
       "      <td>Loser</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>Flight attendant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelor in Paradise</td>\n",
       "      <td>Jade Roper</td>\n",
       "      <td>Loser</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Event Planner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bachelor</td>\n",
       "      <td>Kaity Biggar</td>\n",
       "      <td>Winner</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Golden Bachelor</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>Loser</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>Teacher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Show Name  Contestant Name Winner/Loser  Season  Age  \\\n",
       "0  Bachelor in Paradise       Jade Roper        Loser       2   28   \n",
       "1          The Bachelor  Lauren Bushnell        Loser      20   25   \n",
       "2  Bachelor in Paradise       Jade Roper        Loser       2   28   \n",
       "3          The Bachelor     Kaity Biggar       Winner      27   27   \n",
       "4       Golden Bachelor          Theresa        Loser       1   70   \n",
       "\n",
       "         Occupation  \n",
       "0     Event Planner  \n",
       "1  Flight attendant  \n",
       "2     Event Planner  \n",
       "3             Nurse  \n",
       "4           Teacher  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ff05f",
   "metadata": {},
   "source": [
    "### 2. Training Your Model\n",
    "In the cell seen below, write the code you need to train a linear regression model. Make sure you display the equation of the plane that best fits your chosen data at the end of your program. \n",
    "\n",
    "*Note, level 5 work trains a model using only the standard Python library and Pandas. A level 5 model is trained with at least two features, where one of the features begins as a categorical value (e.g. occupation, hometown, etc.). A level 4 uses external libraries like scikit or numpy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87a9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation of the regression plane:\n",
      "y = nan + (nan * Age) + (nan * Season) + (nan * Occupation_Doctor) + (nan * Occupation_Engineer) + (nan * Occupation_Nurse) + (nan * Occupation_Teacher)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Epena5\\AppData\\Local\\Temp\\ipykernel_10212\\888774101.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  X_train_T_X_train[i][j] /= pivot\n",
      "C:\\Users\\Epena5\\AppData\\Local\\Temp\\ipykernel_10212\\888774101.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  X_train_T_y_train[i] /= pivot\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Age': [22, 25, 27, 29, 30],\n",
    "    'Occupation': ['Nurse', 'Teacher', 'Engineer', 'Artist', 'Doctor'],\n",
    "    'Season': [1, 2, 3, 4, 5],\n",
    "    'Winner': [1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['Occupation'], drop_first=True)\n",
    "\n",
    "X = df_encoded[['Age', 'Season'] + [col for col in df_encoded if col.startswith('Occupation_')]]\n",
    "y = df_encoded['Winner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:4], X[4:], y[:4], y[4:]\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "X_train = [[1] + list(row) for row in X_train]\n",
    "\n",
    "X_train_T = list(zip(*X_train)) \n",
    "X_train_T_X_train = [[sum(a * b for a, b in zip(row, col)) for col in zip(*X_train)] for row in X_train_T]  # X^T * X\n",
    "X_train_T_y_train = [sum(a * b for a, b in zip(row, y_train)) for row in X_train_T]  # X^T * y\n",
    "\n",
    "coefficients = [0] * len(X_train_T_X_train)\n",
    "for i in range(len(X_train_T_X_train)):\n",
    "    pivot = X_train_T_X_train[i][i]\n",
    "    for j in range(i, len(X_train_T_X_train[i])):\n",
    "        X_train_T_X_train[i][j] /= pivot\n",
    "    X_train_T_y_train[i] /= pivot\n",
    "    for k in range(len(X_train_T_X_train)):\n",
    "        if k != i:\n",
    "            factor = X_train_T_X_train[k][i]\n",
    "            for j in range(i, len(X_train_T_X_train[i])):\n",
    "                X_train_T_X_train[k][j] -= factor * X_train_T_X_train[i][j]\n",
    "            X_train_T_y_train[k] -= factor * X_train_T_y_train[i]\n",
    "coefficients = X_train_T_y_train\n",
    "\n",
    "intercept = coefficients[0]\n",
    "feature_coefficients = coefficients[1:]\n",
    "features = ['Age', 'Season'] + [col for col in df_encoded if col.startswith('Occupation_')]\n",
    "equation = f\"y = {intercept:.2f} \" + \" \".join([f\"+ ({coef:.2f} * {feature})\" for coef, feature in zip(feature_coefficients, features)])\n",
    "print(\"Equation of the regression plane:\")\n",
    "print(equation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2b903",
   "metadata": {},
   "source": [
    "### 3. Testing Your Model\n",
    "In the cell seen below, write the code you need to test your linear regression model. \n",
    "\n",
    "*Note, a model is considered a level 5 if it achieves at least 60% prediction accuracy or achieves an RMSE of 2 weeks or less.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce8e043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_regression_model.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "# Dummy data for training\n",
    "X = [[25], [30], [35]]\n",
    "y = [1, 0, 1]\n",
    "\n",
    "# Train and save the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "joblib.dump(model, \"linear_regression_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e00acae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['Show Name', 'Contestant Name', 'Winner/Loser', 'Season', 'Age', 'Occupation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"shows_contestants_1000_rows.csv\")\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns in dataset:\", data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5309c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'target_column' with the correct column name from your dataset\n",
    "correct_target_column = \"Contestant Name\"  # Change this\n",
    "\n",
    "X = data.drop(columns=[correct_target_column])  # Drop only if it exists\n",
    "y = data[correct_target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "928847a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['Show Name', 'Contestant Name', 'Winner/Loser', 'Season', 'Age', 'Occupation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"shows_contestants_1000_rows.csv\")\n",
    "\n",
    "# Display the column names\n",
    "print(\"Columns in dataset:\", data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49195e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"shows_contestants_1000_rows.csv\")\n",
    "\n",
    "# Trim whitespace from column names (fixes the 'Occupation ' issue)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Define the target column\n",
    "target_column = \"Winner/Loser\"  # Update this if your target is different\n",
    "\n",
    "# Check if the target column exists\n",
    "if target_column in data.columns:\n",
    "    X = data.drop(columns=[target_column])  # Features\n",
    "    y = data[target_column]  # Target variable\n",
    "    print(\"Dataset prepared successfully!\")\n",
    "else:\n",
    "    print(f\"Error: Column '{target_column}' not found. Available columns: {data.columns.tolist()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c83219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"shows_contestants_1000_rows.csv\")\n",
    "\n",
    "# Trim whitespace from column names (fixes issues like \"Occupation \")\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Define the target variable\n",
    "target_column = \"Winner/Loser\"\n",
    "\n",
    "# Check if target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Available columns: {data.columns.tolist()}\")\n",
    "\n",
    "# Convert target column to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data[target_column] = label_encoder.fit_transform(data[target_column])  # 'Winner' -> 1, 'Loser' -> 0\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Apply one-hot encoding to categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89e0e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted and ready to use.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "try:\n",
    "    check_is_fitted(model)\n",
    "    print(\"Model is fitted and ready to use.\")\n",
    "except:\n",
    "    print(\"Model is not fitted. Training required.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e50844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1102634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = [1 if pred >= 0.5 else 0 for pred in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26e077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.549457341376641e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3563f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57379710",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'season28_contestants.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10212\\1554676528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load the data for season 28 (replace with your actual data loading method)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"season28_contestants.csv\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Assuming your data is in a CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'season28_contestants.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the data for season 28 (replace with your actual data loading method)\n",
    "data = pd.read_csv(\"season28_contestants.csv\")  # Assuming your data is in a CSV file\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_features = ['Hometown', 'Occupation']  # Adjust based on your data\n",
    "preprocessor.fit(data[categorical_features])\n",
    "\n",
    "# Train a model (using Logistic Regression as an example)\n",
    "# You'll need training data from previous seasons for this part\n",
    "# Replace 'X_train' and 'y_train' with your actual training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)  # Train the model\n",
    "\n",
    "# Make predictions on season 28 data\n",
    "data[\"Prediction\"] = model.predict(preprocessor.transform(data[categorical_features]))\n",
    "\n",
    "# Get the predicted winner\n",
    "predicted_winner = data.loc[data[\"Prediction\"].idxmax(), \"Contestant Name\"]\n",
    "\n",
    "print(\"Predicted Winner:\", predicted_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343eb3f7",
   "metadata": {},
   "source": [
    "### 4. Final Answer\n",
    "\n",
    "In the first cell seen below, state the name of your predicted winner. \n",
    "In the second cell seen below, justify your prediction using an evaluation technique like RMSE or percent accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f82b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37007480",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25533722",
   "metadata": {},
   "source": [
    "#### State the name of your predicted winner here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29adde2",
   "metadata": {},
   "source": [
    "#### Justify your prediction here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
